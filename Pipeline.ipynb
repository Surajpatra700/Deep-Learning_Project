{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2dzNyGh47BHUj5ApfYits",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surajpatra700/Deep-Learning_Project/blob/main/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "teIbP4TmWpoU"
      },
      "outputs": [],
      "source": [
        "# ******************************************************************* INPUT PIPELINES *****************************************************"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In deep learning, an input pipeline is a set of processes that efficiently loads, preprocesses, and feeds data (e.g., images, text, or other types)\n",
        "# into a neural network for training or inference. It ensures data is ready for the model, handles data augmentation, batching, and other tasks\n",
        "# to optimize the training process."
      ],
      "metadata": {
        "id": "24ekExIzXyFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "q_BkEEemX4jJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_sales_number = [21,22,-108,31,-1,32,34,31]"
      ],
      "metadata": {
        "id": "ftaA5JiOGka4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Creating my dataset\n",
        "tf_dataset= tf.data.Dataset.from_tensor_slices(daily_sales_number)\n",
        "tf_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgBXHOBXGznb",
        "outputId": "bcdd1e0d-2fc7-4b44-c18b-939a69c1658a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks1i7GPdG-qY",
        "outputId": "e9ffa872-22be-4924-cb70-744ea89a26cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "22\n",
            "-108\n",
            "31\n",
            "-1\n",
            "32\n",
            "34\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking only 3 Number from the List\n",
        "\n",
        "for sales in tf_dataset.take(3):\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXN9NFBKH-Qk",
        "outputId": "d75131a9-bd33-4fbc-b5dc-9616be17222d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "22\n",
            "-108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LispTsQdICmX",
        "outputId": "725c4ae4-6ffe-4a35-e9dc-93b30dd68ad4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "22\n",
            "31\n",
            "32\n",
            "34\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USD to India Rupees conversion\n",
        "\n",
        "tf_dataset = tf_dataset.map(lambda x: x*72)\n",
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrf5AzCHIjBN",
        "outputId": "3c1a9a83-3ee5-4417-d74b-0ba9ad6d3b57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1512\n",
            "1584\n",
            "2232\n",
            "2304\n",
            "2448\n",
            "2232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_datset = tf_dataset.shuffle(3)\n",
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aJzcCMBI32x",
        "outputId": "dec59a7b-ed58-40b7-e1eb-9cf06bb6767b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1512\n",
            "1584\n",
            "2232\n",
            "2304\n",
            "2448\n",
            "2232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sales_batch in tf_dataset.batch(3):\n",
        "  print(sales_batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExgZ7bKTJ1PD",
        "outputId": "1f9af461-cec8-4ebe-b636-9614ad83e131"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1512 1584 2232]\n",
            "[2304 2448 2232]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Creating all these set of processes in one single line"
      ],
      "metadata": {
        "id": "g1UyXpJgKJ14"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_number)\n",
        "\n",
        "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(2).batch(3)\n",
        "\n",
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mfADXDMKQxR",
        "outputId": "0326fa88-5eb9-456a-f27c-bbcbef3b4933"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1584 1512 2304]\n",
            "[2232 2448 2232]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **************************************** TENSORFLOW DATASETS ******************************"
      ],
      "metadata": {
        "id": "QjqJlg8sL4Gc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "sp9FdvdZV3Rj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(X_train.shape, y_train.shape) , (X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCUIfs9LV7vN",
        "outputId": "28a93545-96f8-4f7e-86c4-af64d31abe66"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "example_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSq_f-kWWWZT",
        "outputId": "8bf7d014-87a2-4fb7-b0f9-1465ef5d175c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(28, 28), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (img, label) in example_dataset:\n",
        "  print(img.numpy().shape, label.numpy())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbKSaHgca0t-",
        "outputId": "a76b77a5-5342-4075-9802-0b3cfc0c17e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(image, label):\n",
        "  return (tf.cast(image, tf.float32)/255.0 , label)\n",
        "\n",
        "example_dataset = example_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "example_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-sJN_jZcN2_",
        "outputId": "e145e9e0-f701-47e7-bf8b-78de1d07a6f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec=(TensorSpec(shape=(28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_dataset = example_dataset.shuffle(len(example_dataset))\n",
        "\n",
        "for (img, label) in example_dataset:\n",
        "  print(img.numpy().shape, label.numpy())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFdsiWRqdlaa",
        "outputId": "c832b886-dc42-49cc-c363-a944e4f2b9e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batching the dataset"
      ],
      "metadata": {
        "id": "nQQcio_OfG0j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_dataset = example_dataset.batch(60)\n",
        "example_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NMVxq9BfkLS",
        "outputId": "d804d2c8-c9a9-4190-f1f1-d2806eca3727"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (img, label) in example_dataset:\n",
        "  print(img.numpy().shape, label.numpy())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw7P0FRufsk7",
        "outputId": "6390caed-3b49-4675-afe7-10ff77d56ede"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 28, 28) [0 3 2 1 0 6 7 7 7 2 2 4 3 0 9 9 4 7 9 0 6 0 3 4 9 1 7 9 5 1 3 9 2 0 4 3 9\n",
            " 9 3 8 2 1 2 4 1 6 3 6 2 6 9 1 1 2 8 6 8 4 8 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "\n",
        "train_dataset = train_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.cache() # cache() helps to store the dataset in cache i.e small high speed memory\n",
        "\n",
        "train_dataset = train_dataset.shuffle(len(train_dataset))\n",
        "train_dataset = train_dataset.batch(50)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB6YHuWpf-3X",
        "outputId": "42a13812-fcec-44e8-cb9d-707962c833e3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "test_dataset = test_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = test_dataset.batch(50)\n",
        "test_dataset = test_dataset.cache() # cache() helps to store the dataset in cache i.e small high speed memory\n",
        "\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzglt_Qjh1jO",
        "outputId": "a6ef4492-eb41-4c09-b39e-7e1cee0e5774"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(28,28)))\n",
        "model.add(layers.Reshape((28,28,1)))\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3,3),strides=(1,1), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3,3),strides=(1,1), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3,3),strides=(1,1), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3,3),strides=(1,1), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3,3),strides=(1,1), activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tHO-LGgi133",
        "outputId": "f9df78da-9e22-4416-8261-d1345052f308"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 22, 22, 8)         584       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 20, 20, 8)         584       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 18, 18, 8)         584       \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 8)                 0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                288       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5146 (20.10 KB)\n",
            "Trainable params: 5146 (20.10 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Cj3ADUXUlEWm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(patience=5) # If validation loss doesnot improve after 5 epochs it will giveUp."
      ],
      "metadata": {
        "id": "OjlII1XHmRHC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data = test_dataset,\n",
        "    callbacks=[es]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYTBCflonX6",
        "outputId": "571ec3be-b537-455c-9953-437fe3d90933"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1200/1200 [==============================] - 23s 6ms/step - loss: 1.7533 - accuracy: 0.3323 - val_loss: 1.2299 - val_accuracy: 0.5511\n",
            "Epoch 2/10\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 1.1019 - accuracy: 0.5852 - val_loss: 0.9776 - val_accuracy: 0.6220\n",
            "Epoch 3/10\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 0.8177 - accuracy: 0.7024 - val_loss: 0.6629 - val_accuracy: 0.7702\n",
            "Epoch 4/10\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 0.5908 - accuracy: 0.7976 - val_loss: 0.4959 - val_accuracy: 0.8298\n",
            "Epoch 5/10\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 0.4540 - accuracy: 0.8513 - val_loss: 0.5389 - val_accuracy: 0.8132\n",
            "Epoch 6/10\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3837 - accuracy: 0.8764 - val_loss: 0.3528 - val_accuracy: 0.8860\n",
            "Epoch 7/10\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 0.3466 - accuracy: 0.8894 - val_loss: 0.3134 - val_accuracy: 0.9044\n",
            "Epoch 8/10\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3224 - accuracy: 0.8969 - val_loss: 0.2808 - val_accuracy: 0.9140\n",
            "Epoch 9/10\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 0.2957 - accuracy: 0.9068 - val_loss: 0.2454 - val_accuracy: 0.9256\n",
            "Epoch 10/10\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 0.2723 - accuracy: 0.9149 - val_loss: 0.2398 - val_accuracy: 0.9277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dd067187eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6kWqyyjpLmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}